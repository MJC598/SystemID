{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an input to the perceptron\n",
    "input_vec = torch.Tensor([0.0, 0.2, 0.3, 0.4])\n",
    "\n",
    "# Choose an activation Function\n",
    "# https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
    "activation = nn.RelU() #nn.Sigmoid() #nn.Tanh() #nn.Softplus()\n",
    "\n",
    "in_features = len(inputs)\n",
    "perceptron = nn.Linear(in_features, 1, bias=True)\n",
    "print(\"Input Vector: {}\".format(input_vec))\n",
    "print(\"Initial Weights: {}\".format(perceptron.weights))\n",
    "print(\"Initial Bias: {}\".format(perceptron.bias))\n",
    "output = activation(perceptron(input_vec))\n",
    "print(\"Output Vector: {}\".format(output))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
